{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1df66c-1b13-4eae-a31c-577317817de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Logistic Regression and saved as logistic_regression.pkl\n",
      "Finished Decision Tree and saved as decision_tree.pkl\n",
      "Finished kNN and saved as knn.pkl\n",
      "Finished Naive Bayes and saved as naive_bayes.pkl\n",
      "Finished Random Forest and saved as random_forest.pkl\n",
      "Finished XGBoost and saved as xgboost.pkl\n",
      "\n",
      "--- FINAL COMPARISON TABLE ---\n",
      "      ML Model Name  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "Logistic Regression  0.819730 0.862004   0.683077 0.595174 0.636103 0.519211\n",
      "      Decision Tree  0.711852 0.632181   0.456233 0.461126 0.458667 0.262356\n",
      "                kNN  0.770759 0.789473   0.573964 0.520107 0.545710 0.393761\n",
      "        Naive Bayes  0.665720 0.837725   0.435864 0.892761 0.585752 0.422170\n",
      "      Random Forest  0.791341 0.837230   0.649057 0.461126 0.539185 0.419267\n",
      "            XGBoost  0.789212 0.839177   0.628378 0.498660 0.556054 0.425070\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score,\n",
    "                             recall_score, f1_score, matthews_corrcoef)\n",
    "\n",
    "# STEP 1: Load Data (Ensure file is uploaded to BITS Lab first)\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# STEP 2: Cleaning (Specific to Telco Dataset)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# STEP 3: Feature Engineering (Dummies ensure > 12 features) [cite: 30]\n",
    "df_final = pd.get_dummies(df, drop_first=True)\n",
    "X = df_final.drop('Churn', axis=1)\n",
    "y = df_final['Churn']\n",
    "\n",
    "# STEP 4: Split and Scale (Crucial for Logistic/kNN)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# STEP 5: Define the 6 Required Models [cite: 32-39]\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# STEP 6: Train, Evaluate, and Save [cite: 40-46, 55]\n",
    "performance_report = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit on scaled data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "   \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "   \n",
    "    # Calculate all 6 metrics\n",
    "    metrics = {\n",
    "        \"ML Model Name\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred)\n",
    "    }\n",
    "    performance_report.append(metrics)\n",
    "   \n",
    "    # Save model file for GitHub 'model/' folder\n",
    "    filename = f\"{name.replace(' ', '_').lower()}.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Finished {name} and saved as {filename}\")\n",
    "\n",
    "# STEP 7: Display Comparison Table for your PDF/README [cite: 71]\n",
    "results_df = pd.DataFrame(performance_report)\n",
    "print(\"\\n--- FINAL COMPARISON TABLE ---\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebd1fa7-8536-4d4d-8c65-ebdc2f526ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STEP 5: COMPARISON TABLE ---\n",
      "      ML Model Name  Accuracy      AUC  Precision   Recall       F1      MCC\n",
      "Logistic Regression  0.819730 0.862004   0.683077 0.595174 0.636103 0.519211\n",
      "      Decision Tree  0.711852 0.632181   0.456233 0.461126 0.458667 0.262356\n",
      "                kNN  0.770759 0.789473   0.573964 0.520107 0.545710 0.393761\n",
      "        Naive Bayes  0.665720 0.837725   0.435864 0.892761 0.585752 0.422170\n",
      "      Random Forest  0.791341 0.837230   0.649057 0.461126 0.539185 0.419267\n",
      "            XGBoost  0.789212 0.839177   0.628378 0.498660 0.556054 0.425070\n",
      "\n",
      "--- STEP 5: OBSERVATION TABLE ---\n",
      "      ML Model Name                                                 Observation about model performance\n",
      "Logistic Regression               Best overall performer with highest Accuracy (0.819) and MCC (0.519).\n",
      "      Decision Tree        Weakest performance; lowest AUC (0.632) and MCC (0.262) suggest overfitting.\n",
      "                kNN           Moderate performance; better than Decision Tree but lacks ensemble power.\n",
      "        Naive Bayes         Highest Recall (0.892) but very low Precision; tends to over-predict churn.\n",
      "      Random Forest Strong ensemble scores; robust but slightly less accurate than Logistic Regression.\n",
      "            XGBoost            Solid AUC (0.839); competitive with Random Forest but needs more tuning.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data from your latest execution output\n",
    "comparison_data = {\n",
    "    \"ML Model Name\": [\"Logistic Regression\", \"Decision Tree\", \"kNN\", \"Naive Bayes\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [0.819730, 0.711852, 0.770759, 0.665720, 0.791341, 0.789212],\n",
    "    \"AUC\": [0.862004, 0.632181, 0.789473, 0.837725, 0.837230, 0.839177],\n",
    "    \"Precision\": [0.683077, 0.456233, 0.573964, 0.435864, 0.649057, 0.628378],\n",
    "    \"Recall\": [0.595174, 0.461126, 0.520107, 0.892761, 0.461126, 0.498660],\n",
    "    \"F1\": [0.636103, 0.458667, 0.545710, 0.585752, 0.539185, 0.556054],\n",
    "    \"MCC\": [0.519211, 0.262356, 0.393761, 0.422170, 0.419267, 0.425070]\n",
    "}\n",
    "\n",
    "# 1. Generate Comparison Table [cite: 188-196]\n",
    "results_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# 2. Define Observations based on your results [cite: 197-198]\n",
    "# These analyze the specific numbers from your latest run\n",
    "observations_data = {\n",
    "    \"ML Model Name\": [\n",
    "        \"Logistic Regression\", \n",
    "        \"Decision Tree\", \n",
    "        \"kNN\", \n",
    "        \"Naive Bayes\", \n",
    "        \"Random Forest\", \n",
    "        \"XGBoost\"\n",
    "    ],\n",
    "    \"Observation about model performance\": [\n",
    "        \"Best overall performer with highest Accuracy (0.819) and MCC (0.519).\",\n",
    "        \"Weakest performance; lowest AUC (0.632) and MCC (0.262) suggest overfitting.\",\n",
    "        \"Moderate performance; better than Decision Tree but lacks ensemble power.\",\n",
    "        \"Highest Recall (0.892) but very low Precision; tends to over-predict churn.\",\n",
    "        \"Strong ensemble scores; robust but slightly less accurate than Logistic Regression.\",\n",
    "        \"Solid AUC (0.839); competitive with Random Forest but needs more tuning.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "obs_df = pd.DataFrame(observations_data)\n",
    "\n",
    "# Print tables for your README and PDF\n",
    "print(\"--- STEP 5: COMPARISON TABLE ---\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n--- STEP 5: OBSERVATION TABLE ---\")\n",
    "print(obs_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba6238-3b90-4dcb-98b7-f68a23dce447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f0178-8b6c-48c5-9432-fbabadf7ede7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
